{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"../../img/ods_stickers.jpg\">\n",
    "## Open Machine Learning Course\n",
    "<center>\n",
    "Authors: [Vitaly Radchenko](https://www.linkedin.com/in/vitaliyradchenk0/), Data Scientist at YouScan, and , Data Scientist at Mail.ru Group <br>\n",
    "Translated and edited by [Yury Kashnitskiy](https://www.linkedin.com/in/festline/), [Egor Polusmak](https://www.linkedin.com/in/egor-polusmak/), [Christina Butsko](https://www.linkedin.com/in/christinabutsko/), [Anna Shirshova](http://linkedin.com/in/anna-shirshova-b908458b), [Artem Trunov](https://www.linkedin.com/in/datamove/),  and [Yuanyuan Pao](https://www.linkedin.com/in/yuanyuanpao/).\n",
    "\n",
    "This material is subject to the terms and conditions of the license [Creative Commons CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/). Free use is permitted for any non-comercial purpose with an obligatory indication of the names of the authors and of the source."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Assignment # 5</center>\n",
    "## <center>Logistic Regression and Random Forest in the credit scoring problem</center>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, you will build models and answer questions using data on credit scoring.\n",
    "\n",
    "Please write your code in the cells with the \"Your code here\" placeholder. Then, answer some questions in this [form](https://drive.google.com/open?id=1P9SAkIRUiznVJd1bzAqRG5AoIpwPfUo3SHfQtDV_tPw).\n",
    "\n",
    "Let's start with a warm-up exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.** There are 5 jurors in a courtroom. Each of them can correctly identify the guilt of the defendant with 70% probability, independent of one another. What is the probability that the jurors will jointly reach the correct verdict if the final decision is made by majority vote?\n",
    "\n",
    "1. 70.00%\n",
    "2. 83.20%\n",
    "3. 83.70%\n",
    "4. 87.50%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Let's move on to machine learning.\n",
    "\n",
    "## Credit scoring problem setup\n",
    "\n",
    "#### Problem\n",
    "\n",
    "Predict whether the customer will repay his/her credit within 90 days. This is a binary classification problem; we will assign customers into good or bad categories based on our prediction.\n",
    "\n",
    "#### Data description\n",
    "\n",
    "| Feature | Variable Type | Value Type | Description |\n",
    "|:--------|:--------------|:-----------|:------------|\n",
    "| age | Input Feature | integer | Customer age |\n",
    "| DebtRatio | Input Feature | real | Total monthly loan payments (loan, alimony, etc.) / Total monthly income percentage |\n",
    "| NumberOfTime30-59DaysPastDueNotWorse | Input Feature | integer | The number of cases when client has overdue 30-59 days (not worse) on other loans during the last 2 years |\n",
    "| NumberOfTimes90DaysLate | Input Feature | integer | Number of cases when customer had 90+dpd overdue on other credits |\n",
    "| NumberOfTime60-89DaysPastDueNotWorse | Input Feature | integer | Number of cased when customer has 60-89dpd (not worse) during the last 2 years |\n",
    "| NumberOfDependents | Input Feature | integer | The number of customer dependents |\n",
    "| SeriousDlqin2yrs | Target Variable | binary: <br>0 or 1 | Customer hasn't paid the loan debt within 90 days |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's set up our environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable warnings in Anaconda\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import rcParams\n",
    "rcParams['figure.figsize'] = 11, 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write the function that will replace *NaN* values with a median for each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_nan(table):\n",
    "    for col in table.columns:\n",
    "        table[col] = table[col].fillna(table[col].median())\n",
    "    return table   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, read the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SeriousDlqin2yrs</th>\n",
       "      <th>age</th>\n",
       "      <th>NumberOfTime30-59DaysPastDueNotWorse</th>\n",
       "      <th>DebtRatio</th>\n",
       "      <th>NumberOfTimes90DaysLate</th>\n",
       "      <th>NumberOfTime60-89DaysPastDueNotWorse</th>\n",
       "      <th>MonthlyIncome</th>\n",
       "      <th>NumberOfDependents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.249908</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8158.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>3870.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>0.456127</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6666.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000190</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10500.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>0.271820</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SeriousDlqin2yrs  age  NumberOfTime30-59DaysPastDueNotWorse    DebtRatio  \\\n",
       "0                 0   64                                     0     0.249908   \n",
       "1                 0   58                                     0  3870.000000   \n",
       "2                 0   41                                     0     0.456127   \n",
       "3                 0   43                                     0     0.000190   \n",
       "4                 1   49                                     0     0.271820   \n",
       "\n",
       "   NumberOfTimes90DaysLate  NumberOfTime60-89DaysPastDueNotWorse  \\\n",
       "0                        0                                     0   \n",
       "1                        0                                     0   \n",
       "2                        0                                     0   \n",
       "3                        0                                     0   \n",
       "4                        0                                     0   \n",
       "\n",
       "   MonthlyIncome  NumberOfDependents  \n",
       "0         8158.0                 0.0  \n",
       "1            NaN                 0.0  \n",
       "2         6666.0                 0.0  \n",
       "3        10500.0                 2.0  \n",
       "4          400.0                 0.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../../data/credit_scoring_sample.csv', sep =';')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the variable types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SeriousDlqin2yrs                          int64\n",
       "age                                       int64\n",
       "NumberOfTime30-59DaysPastDueNotWorse      int64\n",
       "DebtRatio                               float64\n",
       "NumberOfTimes90DaysLate                   int64\n",
       "NumberOfTime60-89DaysPastDueNotWorse      int64\n",
       "MonthlyIncome                           float64\n",
       "NumberOfDependents                      float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check target variable distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of the target:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    0.777511\n",
       "1    0.222489\n",
       "Name: SeriousDlqin2yrs, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
<<<<<<< HEAD
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x206e0b73080>"
=======
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x110e94470>"
>>>>>>> d76a3633c4e34d4cca9b3efb9855b91b151f92b6
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = data['SeriousDlqin2yrs'].hist(orientation='horizontal', color='red')\n",
    "ax.set_xlabel(\"number_of_observations\")\n",
    "ax.set_ylabel(\"unique_value\")\n",
    "ax.set_title(\"Target distribution\")\n",
    "\n",
    "print('Distribution of the target:')\n",
    "data['SeriousDlqin2yrs'].value_counts()/data.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the function to replace *NaN* values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
<<<<<<< HEAD
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age',\n",
       " 'NumberOfTime30-59DaysPastDueNotWorse',\n",
       " 'DebtRatio',\n",
       " 'NumberOfTimes90DaysLate',\n",
       " 'NumberOfTime60-89DaysPastDueNotWorse',\n",
       " 'MonthlyIncome',\n",
       " 'NumberOfDependents']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "independent_columns_names = [x for x in data if x != 'SeriousDlqin2yrs']\n",
    "independent_columns_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the function to replace *NaN* values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
=======
>>>>>>> d76a3633c4e34d4cca9b3efb9855b91b151f92b6
   "outputs": [],
   "source": [
    "table = fill_nan(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate the target variable and input features:"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 9,
=======
   "execution_count": 8,
>>>>>>> d76a3633c4e34d4cca9b3efb9855b91b151f92b6
   "metadata": {},
   "outputs": [],
   "source": [
    "X = table.drop('SeriousDlqin2yrs', axis=1)\n",
    "y = table['SeriousDlqin2yrs']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.** Make an interval estimate of the average age for the customers who delayed repayment at the 90% confidence level. Use the example from the article as reference, if needed. Also, use `np.random.seed(0)` as it was done in the article. What is the resulting interval estimate?\n",
    "\n",
    "1. 52.59 – 52.86\n",
    "2. 45.71 – 46.13\n",
    "3. 45.68 – 46.17\n",
    "4. 52.56 – 52.88"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age of delayed loan payment customers: mean interval [ 45.71379414  46.12700479]\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "np.random.seed(0)\n",
    "\n",
    "\n",
    "def get_bootstrap_samples(data, n_samples):\n",
    "    \"\"\"Generate bootstrap samples using the bootstrap method.\"\"\"\n",
    "    indices = np.random.randint(0, len(data), (n_samples, len(data)))\n",
    "    samples = data[indices]\n",
    "    return samples\n",
    "\n",
    "\n",
    "def stat_intervals(stat, alpha):\n",
    "    \"\"\"Produce an interval estimate.\"\"\"\n",
    "    boundaries = np.percentile(stat, [100 * alpha / 2., 100 * (1 - alpha / 2.)])\n",
    "    return boundaries\n",
    "\n",
    "\n",
    "cust_delay = table[table['SeriousDlqin2yrs']== 1 ]['age'].values\n",
    "\n",
    "delay_mean_scores = [np.mean(sample) \n",
    "                       for sample in get_bootstrap_samples(cust_delay, 1000)]\n",
    "\n",
    "print(\"Age of delayed loan payment customers: mean interval\", stat_intervals(delay_mean_scores, 0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will create a `LogisticRegression` model and use `class_weight='balanced'` to make up for our unbalanced classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(random_state=5, class_weight='balanced')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to find the best regularization coefficient, which is the coefficient `C` for logistic regression. Then, we will have an optimal model that is not overfit and is a good predictor of the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'C': (0.0001, 0.001, 0.01, 0.1, 1, 10)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to find the optimal value of `C`, let's apply stratified 5-fold validation and look at the *ROC AUC* against different values of the parameter `C`. Use the `StratifiedKFold` function for this: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the important metrics of model quality is the *Area Under the Curve (AUC)*. *ROC AUC* varies from 0 to 1. The closer ROC AUC is to 1, the better the quality of the classification model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Question 3.** Perform a *Grid Search* with the scoring metric \"roc_auc\" for the parameter `C`. Which value of the parameter `C` is optimal? \n",
    "\n",
    "1. 0.0001\n",
    "2. 0.001\n",
    "3. 0.01\n",
    "4. 0.1\n",
    "5. 1\n",
    "6. 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "gs = GridSearchCV(estimator=lr , param_grid= parameters,scoring='roc_auc',cv = skf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=5, shuffle=True),\n",
       "       error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=5,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'C': (0.0001, 0.001, 0.01, 0.1, 1, 10)},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=0.001, class_weight='balanced', dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=5,\n",
      "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False) {'C': 0.001} 0.795497778712\n"
     ]
    }
   ],
   "source": [
    "print (gs.best_estimator_, gs.best_params_ , gs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arkajit\\anaconda2\\envs\\tfenv2\\lib\\site-packages\\sklearn\\model_selection\\_search.py:761: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[mean: 0.79033, std: 0.00531, params: {'C': 0.0001},\n",
       " mean: 0.79550, std: 0.00638, params: {'C': 0.001},\n",
       " mean: 0.79070, std: 0.00815, params: {'C': 0.01},\n",
       " mean: 0.78878, std: 0.00822, params: {'C': 0.1},\n",
       " mean: 0.78867, std: 0.00832, params: {'C': 1},\n",
       " mean: 0.78890, std: 0.00792, params: {'C': 10}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.grid_scores_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.** Can we consider the best model stable? Let's call the model *stable* if standard deviation of it's scores in cross-validation is less than $5*10^{-3}$. Save the *ROC AUC* value of the best model; it will be useful for the following tasks.\n",
    "\n",
    "1. Yes\n",
    "2. No"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([ 0.63019843,  0.69758739,  0.79150243,  0.78433633,  0.80869846,\n",
       "         0.77187476]),\n",
       " 'mean_score_time': array([ 0.02499909,  0.00625215,  0.        ,  0.        ,  0.00312233,\n",
       "         0.01250172]),\n",
       " 'mean_test_score': array([ 0.79033283,  0.79549778,  0.79069818,  0.78878227,  0.78867366,\n",
       "         0.78890314]),\n",
       " 'mean_train_score': array([ 0.79073548,  0.79590814,  0.7912098 ,  0.78928693,  0.78912982,\n",
       "         0.78936514]),\n",
       " 'param_C': masked_array(data = [0.0001 0.001 0.01 0.1 1 10],\n",
       "              mask = [False False False False False False],\n",
       "        fill_value = ?),\n",
       " 'params': [{'C': 0.0001},\n",
       "  {'C': 0.001},\n",
       "  {'C': 0.01},\n",
       "  {'C': 0.1},\n",
       "  {'C': 1},\n",
       "  {'C': 10}],\n",
       " 'rank_test_score': array([3, 1, 2, 5, 6, 4]),\n",
       " 'split0_test_score': array([ 0.78867902,  0.79501895,  0.79187854,  0.78944043,  0.78904763,\n",
       "         0.78904593]),\n",
       " 'split0_train_score': array([ 0.78943702,  0.79465672,  0.79117821,  0.788629  ,  0.78827951,\n",
       "         0.7882784 ]),\n",
       " 'split1_test_score': array([ 0.79339284,  0.79740443,  0.7894569 ,  0.78715209,  0.78813721,\n",
       "         0.78812398]),\n",
       " 'split1_train_score': array([ 0.78802488,  0.79285913,  0.78683969,  0.78497871,  0.78585036,\n",
       "         0.78583834]),\n",
       " 'split2_test_score': array([ 0.79316483,  0.79784779,  0.79226605,  0.79052059,  0.7902388 ,\n",
       "         0.79021089]),\n",
       " 'split2_train_score': array([ 0.79163306,  0.79716265,  0.79178572,  0.79011189,  0.78984787,\n",
       "         0.78982223]),\n",
       " 'split3_test_score': array([ 0.7807311 ,  0.78393658,  0.7771806 ,  0.77553366,  0.77488457,\n",
       "         0.77609726]),\n",
       " 'split3_train_score': array([ 0.79461137,  0.79921913,  0.79420415,  0.79287856,  0.79213964,\n",
       "         0.79339157]),\n",
       " 'split4_test_score': array([ 0.79569639,  0.80328104,  0.80270869,  0.80126461,  0.80106004,\n",
       "         0.80103769]),\n",
       " 'split4_train_score': array([ 0.78997105,  0.79564304,  0.79204121,  0.78983649,  0.78953171,\n",
       "         0.78949514]),\n",
       " 'std_fit_time': array([ 0.06373451,  0.07154207,  0.05749855,  0.04811144,  0.07139613,\n",
       "         0.05895114]),\n",
       " 'std_score_time': array([ 0.0272512 ,  0.00765729,  0.        ,  0.        ,  0.00624466,\n",
       "         0.00625086]),\n",
       " 'std_test_score': array([ 0.00531173,  0.00638145,  0.00815289,  0.00821492,  0.00832365,\n",
       "         0.00791903]),\n",
       " 'std_train_score': array([ 0.00225592,  0.00216653,  0.00241197,  0.00256421,  0.00205981,\n",
       "         0.00245183])}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "gs.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature importance\n",
    "\n",
    "**Question 5.** *Feature importance* is defined by the absolute value of its corresponding coefficient. First, you need to normalize all of the feature values so that it will be valid to compare them (here you resort to `StandardScaler`). What is the most important feature for the best logistic regression model?\n",
    "\n",
    "1. age\n",
    "2. NumberOfTime30-59DaysPastDueNotWorse\n",
    "3. DebtRatio\n",
    "4. NumberOfTimes90DaysLate\n",
    "5. NumberOfTime60-89DaysPastDueNotWorse\n",
    "6. MonthlyIncome\n",
    "7. NumberOfDependents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer\n",
    "norm = Normalizer()\n",
    "sc= StandardScaler()\n",
    "#X_ = norm.fit_transform(X)\n",
    "X_= sc.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.001, class_weight='balanced', dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=-1, penalty='l2', random_state=5,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr2 = LogisticRegression(C=0.001, class_weight='balanced',random_state=5,n_jobs=-1)\n",
    "lr2.fit(X_,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.41630368,  0.72400432, -0.02408186,  0.51767292,  0.19473217,\n",
       "       -0.16286353,  0.10132603])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr2.coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arkajit\\anaconda2\\envs\\tfenv2\\lib\\site-packages\\sklearn\\model_selection\\_search.py:761: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[mean: 0.79033, std: 0.00531, params: {'C': 0.0001},\n",
       " mean: 0.79550, std: 0.00638, params: {'C': 0.001},\n",
       " mean: 0.79070, std: 0.00815, params: {'C': 0.01},\n",
       " mean: 0.78878, std: 0.00822, params: {'C': 0.1},\n",
       " mean: 0.78867, std: 0.00832, params: {'C': 1},\n",
       " mean: 0.78890, std: 0.00792, params: {'C': 10}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.grid_scores_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 6.** What's the effect of  `DebtRatio` on the prediction made with Logistic regression? Calculate this with the [softmax function](https://en.wikipedia.org/wiki/Softmax_function)\n",
    "\n",
    "1. 0.38\n",
    "2. -0.02\n",
    "3. 0.11\n",
    "4. 0.24"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 24,
=======
   "execution_count": 9,
>>>>>>> d76a3633c4e34d4cca9b3efb9855b91b151f92b6
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "import math\n",
    "def sftmx(x):\n",
    "    \n",
    "    x_exp = [round(math.exp(round(i,3)),3) for i in x]\n",
    "    sum_x_exp= round(sum(x_exp),3)\n",
    "       \n",
    "    return [round((i/ sum_x_exp),3) for i in x_exp]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.155, 0.211, 0.105, 0.172, 0.124, 0.12, 0.113]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sftmx(abs(lr2.coef_[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 7.** Let's see how we can interpret the impact of our features. For this, re-train logistic regression with original features, that is, not scaled. Next, modify the customer's age by adding 20 years, keeping the other features unchanged. You'll have two estimates for odds of this customer being bad – with original age and with aged increased by 20 years. What's the quotient of this odds? (the second divided by the first). That is, you'll find how more or less likely it is that a customer won't repay his/her credit if he/she were 20 years older. You can find some material on interpreting logistic regression coefficients [here](https://www.unm.edu/~schrader/biostat/bio2/Spr06/lec11.pdf).\n",
    "\n",
    "1. -0.01\n",
    "2. 0.70\n",
    "3. 8.32\n",
    "4. 0.66"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.001, class_weight='balanced', dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=5,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "\n",
    "lr3 = LogisticRegression(C=0.001 , random_state=5 , class_weight='balanced')\n",
    "lr3.fit(X,y)\n"
   ]
  },
  {
<<<<<<< HEAD
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    " X_age20 = X.copy()\n",
    "X_age20['age']= X_age20 +20"
   ]
  },
  {
=======
>>>>>>> d76a3633c4e34d4cca9b3efb9855b91b151f92b6
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr3.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr3.predict(X_age20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.802631870936 0.827397199476\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix , accuracy_score\n",
    "print(accuracy_score(lr3.predict(X),y.as_matrix()),accuracy_score(lr3.predict(X_age20),y.as_matrix()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[30408,  4265],\n",
       "       [ 4629,  5761]], dtype=int64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(lr3.predict(X),y.as_matrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[33056,  5797],\n",
       "       [ 1981,  4229]], dtype=int64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(lr3.predict(X_age20),y.as_matrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6210"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(lr3.predict(X_age20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10390"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(lr3.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10026"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.59769008662175171"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(lr3.predict(X_age20))/sum(lr3.predict(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the Random Forest classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize Random Forest with 100 trees and balance target classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, n_jobs=-1, random_state=42, \n",
    "                            class_weight='balanced')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to search for the best hyperparameters among these values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'max_features': [1, 2, 4], \n",
    "              'min_samples_leaf': [3, 5, 7, 9], \n",
    "              'max_depth': [5,10,15]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, we will use stratified k-fold validation again. You should still have the `skf` variable defined."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 8.** How much higher is the *ROC AUC* of the best random forest model than that of the best logistic regression on validation? Use `GridSearchCV` and it's attribute `best_score_`.\n",
    "\n",
    "1. 0.04\n",
    "2. 0.03\n",
    "3. 0.02\n",
    "4. 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-407b9965c3da>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Your code here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mgs2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'roc_auc'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mskf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mgs2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\arkajit\\anaconda2\\envs\\tfenv2\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    637\u001b[0m                                   error_score=self.error_score)\n\u001b[0;32m    638\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[1;32m--> 639\u001b[1;33m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    640\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m         \u001b[1;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\arkajit\\anaconda2\\envs\\tfenv2\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    777\u001b[0m             \u001b[1;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m             \u001b[1;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\arkajit\\anaconda2\\envs\\tfenv2\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    623\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    624\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 625\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    626\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\arkajit\\anaconda2\\envs\\tfenv2\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 588\u001b[1;33m         \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\arkajit\\anaconda2\\envs\\tfenv2\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\arkajit\\anaconda2\\envs\\tfenv2\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    330\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 332\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    333\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\arkajit\\anaconda2\\envs\\tfenv2\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\arkajit\\anaconda2\\envs\\tfenv2\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\arkajit\\anaconda2\\envs\\tfenv2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[0;32m    456\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    457\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 458\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    459\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    460\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\arkajit\\anaconda2\\envs\\tfenv2\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    326\u001b[0m                     \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    327\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[1;32m--> 328\u001b[1;33m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[0;32m    329\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m             \u001b[1;31m# Collect newly grown trees\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\arkajit\\anaconda2\\envs\\tfenv2\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    787\u001b[0m                 \u001b[1;31m# consumption.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 789\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    790\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\arkajit\\anaconda2\\envs\\tfenv2\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    697\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    698\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 699\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    700\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\arkajit\\anaconda2\\envs\\tfenv2\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 638\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    639\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mready\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    640\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\arkajit\\anaconda2\\envs\\tfenv2\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 635\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\arkajit\\anaconda2\\envs\\tfenv2\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    550\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 551\u001b[1;33m                 \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    552\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\arkajit\\anaconda2\\envs\\tfenv2\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    293\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 295\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "gs2 = GridSearchCV(estimator=rf, param_grid=parameters,scoring='roc_auc',cv = skf)\n",
    "gs2.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (gs2.best_estimator_, gs2.best_params_ , gs2.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs2.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs2.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 9.** What feature has the weakest impact in the Random Forest model?\n",
    "\n",
    "1. age\n",
    "2. NumberOfTime30-59DaysPastDueNotWorse\n",
    "3. DebtRatio\n",
    "4. NumberOfTimes90DaysLate\n",
    "5. NumberOfTime60-89DaysPastDueNotWorse\n",
    "6. MonthlyIncome\n",
    "7. NumberOfDependents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "            criterion='gini', max_depth=10, max_features=2,\n",
       "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "            min_impurity_split=None, min_samples_leaf=7,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=100, n_jobs=-1, oob_score=False, random_state=42,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "rf2 = RandomForestClassifier(n_estimators=100,max_depth=10,max_features=2, min_samples_leaf=7, n_jobs=-1, random_state=42, \n",
    "                            class_weight='balanced')\n",
    "rf2.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.11592643,  0.30246139,  0.07951983,  0.27864363,  0.14868317,\n",
       "        0.06042863,  0.01433692])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf2.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 10.** What is the most significant advantage of using *Logistic Regression* versus *Random Forest* for this problem?\n",
    "\n",
    "1. Spent less time for model fitting;\n",
    "2. Fewer variables to iterate;\n",
    "3. Feature interpretability;\n",
    "4. Linear properties of the algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import modules and set up the parameters for bagging:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.model_selection import cross_val_score, RandomizedSearchCV\n",
    "\n",
    "parameters = {'max_features': [2, 3, 4], 'max_samples': [0.5, 0.7, 0.9], \n",
    "              'base_estimator__C': [0.0001, 0.001, 0.01, 1, 10, 100]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 11.** Fit a bagging classifier with `random_state=42`. For the base classifiers, use 100 logistic regressors and use `RandomizedSearchCV` instead of `GridSearchCV`. It will take a lot of time to iterate over all 54 variants, so set the maximum number of iterations for `RandomizedSearchCV` to 20. Don't forget to set the parameters `cv` and `random_state=1`. What is the best *ROC AUC* you achieve?\n",
    "\n",
    "1. 80.75%\n",
    "2. 80.12%\n",
    "3. 79.62%\n",
    "4. 76.50%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'max_iter'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-9ed0bdc6e68e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mbag\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBaggingClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mrs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomizedSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbag\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;36m20\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mskf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mrs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'max_iter'"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "\n",
    "bag = BaggingClassifier(LogisticRegression(),n_estimators=100, random_state=42 )\n",
    "\n",
    "rs = RandomizedSearchCV(estimator=bag,max_iter= 20 , n_jobs=-1,random_state=1,cv=skf,param_distributions=parameters)\n",
    "\n",
    "rs.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'base_estimator__C': 10, 'max_features': 4, 'max_samples': 0.5}"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78479018263320244"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arkajit\\anaconda2\\envs\\tfenv2\\lib\\site-packages\\sklearn\\model_selection\\_search.py:761: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[mean: 0.78159, std: 0.00094, params: {'max_samples': 0.5, 'max_features': 3, 'base_estimator__C': 1},\n",
       " mean: 0.78009, std: 0.00066, params: {'max_samples': 0.9, 'max_features': 2, 'base_estimator__C': 0.0001},\n",
       " mean: 0.78426, std: 0.00139, params: {'max_samples': 0.9, 'max_features': 4, 'base_estimator__C': 10},\n",
       " mean: 0.78171, std: 0.00086, params: {'max_samples': 0.9, 'max_features': 3, 'base_estimator__C': 1},\n",
       " mean: 0.78173, std: 0.00098, params: {'max_samples': 0.7, 'max_features': 3, 'base_estimator__C': 1},\n",
       " mean: 0.78033, std: 0.00077, params: {'max_samples': 0.9, 'max_features': 2, 'base_estimator__C': 100},\n",
       " mean: 0.78468, std: 0.00138, params: {'max_samples': 0.7, 'max_features': 4, 'base_estimator__C': 1},\n",
       " mean: 0.78173, std: 0.00098, params: {'max_samples': 0.7, 'max_features': 3, 'base_estimator__C': 10},\n",
       " mean: 0.78035, std: 0.00082, params: {'max_samples': 0.7, 'max_features': 2, 'base_estimator__C': 100},\n",
       " mean: 0.78026, std: 0.00081, params: {'max_samples': 0.7, 'max_features': 2, 'base_estimator__C': 0.01},\n",
       " mean: 0.78006, std: 0.00069, params: {'max_samples': 0.7, 'max_features': 2, 'base_estimator__C': 0.001},\n",
       " mean: 0.78009, std: 0.00066, params: {'max_samples': 0.5, 'max_features': 3, 'base_estimator__C': 0.0001},\n",
       " mean: 0.78120, std: 0.00083, params: {'max_samples': 0.5, 'max_features': 3, 'base_estimator__C': 0.01},\n",
       " mean: 0.78171, std: 0.00086, params: {'max_samples': 0.9, 'max_features': 3, 'base_estimator__C': 100},\n",
       " mean: 0.78162, std: 0.00098, params: {'max_samples': 0.5, 'max_features': 3, 'base_estimator__C': 10},\n",
       " mean: 0.78479, std: 0.00114, params: {'max_samples': 0.5, 'max_features': 4, 'base_estimator__C': 10},\n",
       " mean: 0.78379, std: 0.00141, params: {'max_samples': 0.5, 'max_features': 4, 'base_estimator__C': 0.01},\n",
       " mean: 0.78466, std: 0.00133, params: {'max_samples': 0.7, 'max_features': 4, 'base_estimator__C': 100},\n",
       " mean: 0.78171, std: 0.00086, params: {'max_samples': 0.9, 'max_features': 3, 'base_estimator__C': 10},\n",
       " mean: 0.78428, std: 0.00141, params: {'max_samples': 0.9, 'max_features': 4, 'base_estimator__C': 1}]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs.grid_scores_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Question 12.** Give an interpretation of the best parameters for bagging. Why are these values of `max_features` and `max_samples` the best?\n",
    "\n",
    "1. For bagging it's important to use as few features as possible;\n",
    "2. Bagging works better on small samples;\n",
    "3. Less correlation between single models;\n",
    "4. The higher the number of features, the lower the loss of information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
