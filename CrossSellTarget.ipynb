{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "mingw_path = 'C:\\\\mingw-w64\\\\x86_64-5.3.0-posix-seh-rt_v4-rev0\\\\mingw64\\\\bin'\n",
    "\n",
    "os.environ['PATH'] = mingw_path + ';' + os.environ['PATH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xg\n",
    "import datetime\n",
    "import sklearn.preprocessing as pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arkajit\\Anaconda2\\envs\\TFENV\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2718: DtypeWarning: Columns (8,11,12,13,14,15,16,17,18,19,21,23,26,28,29,30,32,82,83,85,91,269,325,326,327,328) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('CrossSellTarget\\\\Train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arkajit\\Anaconda2\\envs\\TFENV\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2718: DtypeWarning: Columns (8,11,12,13,14,15,16,17,18,19,26,28,29,30,82,83,85,91,269,325,326,327,328) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv('CrossSellTarget\\\\Test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data_dict = pd.read_csv('CrossSellTarget\\\\data_dict.csv')\n",
    "data_dict.drop(['Unnamed: 2','Unnamed: 3'],axis=1, inplace=True)\n",
    "data_dict.index= data_dict['VARIABLE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def confusion_mat(train,y_train,col,val): \n",
    "    m_y=[]\n",
    "    m_n=[]\n",
    "    for i in range(len(val)):\n",
    "        m_y.append(0)\n",
    "        m_n.append(0)\n",
    "    \n",
    "    for i in train.index.values:\n",
    "        for j in range(len(val)):\n",
    "            if( train.get_value(i,col) == val[j]) and (y_train.get_value(i) == 'Y'):\n",
    "                m_y[j]+=1\n",
    "            elif( train.get_value(i,col) == val[j]) and (y_train.get_value(i) == 'N'):\n",
    "                m_n[j]+=1\n",
    "    print '\\tyes','\\tno','\\t%yes','\\t%no','\\n'\n",
    "    for i in range(len(val)):\n",
    "        print val[i],'\\t',m_y[i],'\\t',m_n[i],'\\t',100 * m_y[i]/(m_y[i] + m_n[i]),'%','\\t',100 * m_n[i]/(m_y[i] + m_n[i]),'%','\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count=0\n",
    "b_col=[]\n",
    "c_col=[]\n",
    "for i in train.columns:\n",
    "    if len(train[i].astype('category').cat.categories.get_values()) <= 3:\n",
    "        if train[i].isnull().sum()<50000:\n",
    "            #count+=1\n",
    "            b_col.append([i,list(train[i].astype('category').cat.categories.get_values())])\n",
    "    elif len(train[i].astype('category').cat.categories.get_values()) > 3:\n",
    "        if train[i].isnull().sum()<50000:\n",
    "            count+=1\n",
    "            c_col.append(i)\n",
    "    \n",
    "        \n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ACT_TYPE', ['CSA', 'SA']] ACCOUNT TYPE - SAVING, CURRENT OR SALARY ACCOUNT 0\n",
      "['CARD_AUTOMOBILE_MON_01', ['N', 'Y']] TOTAL SPEND THROUGH DEBIT AND CREDIT CARD ON AUTOMOBILE CATEGORY IN MON_01 0\n",
      "['CARD_ENTMNT_MON_01', ['N', 'Y']] TOTAL SPEND THROUGH DEBIT AND CREDIT CARD ON ENTERTAINMENT CATEGORY IN MON_01 0\n",
      "['CARD_HOBBY_MON_01', ['N', 'Y']] TOTAL SPEND THROUGH DEBIT AND CREDIT CARD ON HOBBY CATEGORY IN MON_01 0\n",
      "['CARD_HOME_DECOR_MON_01', ['N', 'Y']] TOTAL SPEND THROUGH DEBIT AND CREDIT CARD ON HOME AND DECOR CATEGORY IN MON_01 0\n",
      "['CARD_HOTEL_MON_01', ['N', 'Y']] TOTAL SPEND THROUGH DEBIT AND CREDIT CARD ON HOTEL CATEGORY IN MON_01 0\n",
      "['CARD_JEWELLERY_MON_01', ['N', 'Y']] TOTAL SPEND THROUGH DEBIT AND CREDIT CARD ON JEWELLERY CATEGORY IN MON_01 0\n",
      "['CARD_MEDICAL_MON_01', ['N', 'Y']] TOTAL SPEND THROUGH DEBIT AND CREDIT CARD ON MEDICAL CATEGORY IN MON_01 0\n",
      "['CARD_PRSNL_CARE_MON_01', ['N', 'Y']] TOTAL SPEND THROUGH DEBIT AND CREDIT CARD ON PERSONAL CARECATEGORY IN MON_01 0\n",
      "['CARD_RESTAURANT_MON_01', ['N', 'Y']] TOTAL SPEND THROUGH DEBIT AND CREDIT CARD ON RESTAURANT CATEGORY IN MON_01 0\n",
      "['CARD_TRAVEL_MON_01', ['N', 'Y']] TOTAL SPEND THROUGH DEBIT AND CREDIT CARD ON TRAVEL CATEGORY IN MON_01 0\n",
      "['CC_ACTIVE', ['N', 'Y']] CREDIT_CARD_ACTIVE IN LAST 3 MONTHS 0\n",
      "['CC_HOLD', ['N', 'Y']] CREDIT_CARD_HOLDING_TAG _MON_01 0\n",
      "['CHANNEL_CLICK_DISP', ['CLICK', 'DISP', 'NONE']] TAGGED AS CLICK OR DISPLAY IF CUSTOMER CLICKED OR WAS DISPLAYED CAMPAIGN ACROSS ANY OF THE  CHANNEL I.E. ATM, EMAIL, NETBANKING  0\n",
      "['COC_ELIGIBLE', [0, 1]] Y TAG IF CUSTOMER IS ELIGIBLE FOR COC 0\n",
      "['DC_ACTIVE', ['N', 'Y']] DEBIT_CARD_ACTIVE IN LAST 3 MONTHS 0\n",
      "['DC_HOLD', ['N', 'Y']] DEBIT_CARD_HOLDING_TAG_MON_01  0\n",
      "['FINANCE_MON_01', ['N', 'Y']] TAGGED AS Y IF CUSTOMER VISITED FINANCE ASSISTANCE WEBSITES SUCH AS BANK BAZAAR, POLICY BAZZAR ETC FOR MON_01 0\n",
      "['GENDER', ['F', 'M']] GENDER  87\n",
      "['INMON_01KET_MON_01', ['N', 'Y']] TAGGED AS Y IF CUSTOMER VISITED SUCH AS MAGIC BRICKS ETC FOR MON_01 0\n",
      "['JOBS_MON_01', ['N', 'Y']] TAGGED AS Y IF CUSTOMER VISITED JOB SITE DATA  SUCH AS NAUKRI, INDEED ETC FOR MON_01 0\n",
      "['LIFESTYLE_MON_01', ['N', 'Y']] TAGGED AS Y IF CUSTOMER VISITED LIFESTYLE SITE SUCH AS FLIPKART, AMAZON ETC FOR MON_01 0\n",
      "['PL2CC_ELIGIBLE', [0, 1]] TAGGED AS Y IF  CUST IS ELIGIBLE FOR JUMBO LOAN 0\n",
      "['TOP14_CITY', ['N', 'Y']] CUSTOMER LIVING IN TOP 14 CITIES IDENTIFIED BASIS INTERNAL LOGIC 0\n",
      "['TOP9_CITY', ['N', 'Y']] CUSTOMER LIVING IN TOP 9 CITIES IDENTIFIED BASIS INTERNAL LOGIC 0\n",
      "['TOP_CORP_TAG', ['NONE', 'TOP_100', 'TOP_800']] TOP COMPANY  TAG  (1/0) TAG 0\n",
      "['TRAVEL_MON_01', ['N', 'Y']] TAGGED AS Y IF CUSTOMER VISITED TRAVEL SITES SUCH AS MAKE MY TRIP ETC FOR MON_01 0\n"
     ]
    }
   ],
   "source": [
    "for col in sorted(b_col):\n",
    "    print col ,data_dict.get_value(col[0],'DESCRIPTIONS'),train[col[0]].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tyes \tno \t%yes \t%no \n",
      "\n",
      "0 \t3817 \t264687 \t1 % \t98 % \n",
      "\n",
      "1 \t795 \t30701 \t2 % \t97 % \n",
      "\n"
     ]
    }
   ],
   "source": [
    "confusion_mat(train,y_train,'COC_ELIGIBLE', [0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AMB_MON_01  , mean:  , no.of nan: 0\n",
      "  MONTHLY BALANCE IN MON_01\n",
      "AMB_MON_02  , mean:  , no.of nan: 992\n",
      "  MONTHLY BALANCE IN MON_02\n",
      "AMB_MON_03  , mean:  , no.of nan: 2778\n",
      "  MONTHLY BALANCE IN MON_03\n",
      "AMB_MON_04  , mean:  , no.of nan: 5622\n",
      "  MONTHLY BALANCE IN MON_04\n",
      "EOP_BAL_MON_01  , mean:  , no.of nan: 0\n",
      "  END OF PERIOD BALANCE IN MON_01\n",
      "EOP_MON_02  , mean:  , no.of nan: 989\n",
      "  END OF PERIOD BALANCE FOR MON_02\n",
      "EOP_MON_03  , mean:  , no.of nan: 2768\n",
      "  END OF PERIOD BALANCE FOR MON_03\n",
      "N_CASA_MAX_BALANCE_MTD  , mean:  , no.of nan: 0\n",
      "  CASA MAXIMUM BALANCE - MAXIMUM ACCOUNT BALANCE FOR MON1\n",
      "N_CASA_MIN_BALANCE_MTD  , mean:  , no.of nan: 0\n",
      "  CASA MINIMUM BALANCE - MINIMUM ACCOUNT BALANCE FOR MON1\n",
      "SCRUB_EMI  , mean:  , no.of nan: 0\n",
      "  MONTHLY TOTAL EMI PAID TO OTHER BANK FOR THE ACTIVE LOANS\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count=0\n",
    "for col in sorted(c_col):\n",
    "    if (str(train[col].dtype) == 'float64') or (str(train[col].dtype) == 'float32'):\n",
    "        #continue\n",
    "        count+=1\n",
    "        print col,' , mean:',' , no.of nan:',train[col].isnull().sum()\n",
    "        print ' ',data_dict.get_value(col,'DESCRIPTIONS')\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col in sorted(c_col):\n",
    "    if (str(train[col].dtype) == 'float64') or (str(train[col].dtype) == 'float32'):\n",
    "        if(col.startswith('C') or col.startswith('D')):\n",
    "            print col#,' , mean:',train[col].median(),' , no.of nan:' ,train[col].isnull().sum()\n",
    "            print data_dict.get_value(col,'DESCRIPTIONS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def missing_values_table(df): \n",
    "        mis_val = df.isnull().sum()\n",
    "        mis_val_percent = 100 * df.isnull().sum()/len(df)\n",
    "        mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n",
    "        mis_val_table_ren_columns = mis_val_table.rename(\n",
    "        columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n",
    "        return mis_val_table_ren_columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mis_val_table_ren_columns = missing_values_table(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nan_col = list(mis_val_table_ren_columns[mis_val_table_ren_columns['% of Total Values']>= 80].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "234"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nan_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.drop(nan_col,axis=1 , inplace=True)\n",
    "test.drop(nan_col,axis=1 , inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = train['RESPONDERS']\n",
    "train.drop(['RESPONDERS'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zip_tr= train['ZIP_CODE_FINAL']\n",
    "zip_ts= test['ZIP_CODE_FINAL']\n",
    "train.drop(['ZIP_CODE_FINAL'] , inplace = True , axis = 1)\n",
    "test.drop(['ZIP_CODE_FINAL'] , inplace = True , axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ind=[]\n",
    "for ix,row in train.iterrows():\n",
    "    if row.isnull().sum() > 50 :\n",
    "        ind.append(ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "299426"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(ind) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.reset_index(drop=True,inplace=True)\n",
    "y_train.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(train.index[ind],axis=0,inplace=True)\n",
    "y_train.drop(y_train.index[ind],axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col in train.columns.values:\n",
    "    if(len(train[col].unique()) == 1):\n",
    "        nan_col.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.dropna(axis=1,how='all' ,inplace=True)\n",
    "test.dropna(axis=1,how='all',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in train.columns:\n",
    "    if len(train[i].astype('category').cat.categories.get_values()) <= 3:\n",
    "        train[i] = train[i].astype('category').cat.codes\n",
    "        test[i] = test[i].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in train.columns:\n",
    "    if (len(train[i].astype('category').cat.categories.get_values()) > 3) & (str(train[i].dtype) == 'object'):\n",
    "        #print train[i].isnull().sum(), i \n",
    "        train[i] = train[i].astype('category').cat.codes\n",
    "        test[i] = test[i].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cat_cols=['LEGAL_ENTITY','DESIGNATION_FINAL','PA_PQ_TAG','NEFT_CC_CATEGORY',\n",
    "          'NEFT_DC_CATEGORY','TPT_DC_CATEGORY_MON_01','TPT_CC_CATEGORY_MON_01','IMPS_CC_CATEGORY_MON_01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LEGAL_ENTITY\n",
      "DESIGNATION_FINAL\n",
      "PA_PQ_TAG\n",
      "NEFT_CC_CATEGORY\n",
      "NEFT_DC_CATEGORY\n",
      "TPT_DC_CATEGORY_MON_01\n",
      "TPT_CC_CATEGORY_MON_01\n",
      "IMPS_CC_CATEGORY_MON_01\n"
     ]
    }
   ],
   "source": [
    "for col in cat_cols:\n",
    "    print (col)\n",
    "    train[col] = train[col].apply(lambda x: x if str(x)  != str(pd.np.nan) else '-1' )\n",
    "    test[col] = test[col].apply(lambda x: x if str(x)  != str(pd.np.nan) else '-1' )\n",
    "    train[col] = train[col].astype('str')\n",
    "    test[col] = test[col].astype('str')\n",
    "    data= test[col].append(train[col])\n",
    "    data = data.astype('str')\n",
    "    le = pp.LabelEncoder().fit(data)\n",
    "    train[col] = le.transform(train[col])\n",
    "    test[col] = le.transform(test[col])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = pp.LabelEncoder().fit(y_train)\n",
    "y_train = le.transform(y_train)\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in train.columns.values:\n",
    "    train[col] = train[col].apply(lambda x: x if str(x) != str(pd.np.nan) else -1)\n",
    "    test[col] = test[col].apply(lambda x: x if str(x) != str(pd.np.nan) else -1)\n",
    "    #print (col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.index = train['CUSTOMER_ID']\n",
    "train.drop(['CUSTOMER_ID'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test.index = test['CUSTOMER_ID']\n",
    "test.drop(['CUSTOMER_ID'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cor = train.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, ['D_AMT_L3_MON_06', 'N_CASA_MAX_BALANCE_MTD'], '=> ', 0.83314137462414684)\n",
      "(2, ['C_AMT_L3_MON_06', 'N_CASA_MAX_BALANCE_MTD'], '=> ', 0.83425485359091389)\n",
      "(3, ['MAX_C_AMT_L3_MON_06', 'N_CASA_MAX_BALANCE_MTD'], '=> ', 0.83788192479180201)\n",
      "(4, ['D_AMT_L3_MON_01', 'N_CASA_MAX_BALANCE_MTD'], '=> ', 0.81430503884884742)\n",
      "(5, ['C_AMT_L3_MON_01', 'N_CASA_MAX_BALANCE_MTD'], '=> ', 0.83371098989266712)\n",
      "(6, ['MAX_C_AMT_L3_MON_01', 'N_CASA_MAX_BALANCE_MTD'], '=> ', 0.90039793340523677)\n",
      "(7, ['CC_HOLD_MON_02', 'CC_HOLD_MON_03'], '=> ', 0.96362615053033573)\n",
      "(8, ['CC_HOLD_MON_01', 'CC_HOLD_MON_03'], '=> ', 0.92163818236690787)\n",
      "(9, ['CC_HOLD', 'CC_HOLD_MON_03'], '=> ', 0.95819185038176835)\n",
      "(10, ['CC_HOLD_MON_01', 'CC_HOLD_MON_02'], '=> ', 0.95710208721612922)\n",
      "(11, ['CC_HOLD', 'CC_HOLD_MON_02'], '=> ', 0.96162821241166807)\n",
      "(12, ['CC_HOLD', 'CC_HOLD_MON_01'], '=> ', 0.96566490439999564)\n",
      "(13, ['CC_ACTIVE', 'CC_HOLD_MON_01'], '=> ', 0.81041442650381323)\n",
      "(14, ['STMT_MON_02', 'STMT_MON_03'], '=> ', 0.83456203337474399)\n",
      "(15, ['STMT_MON_01', 'STMT_MON_02'], '=> ', 0.83610778251251938)\n",
      "(16, ['AMB_MON_01', 'EOP_BAL_MON_01'], '=> ', 0.86331533618208878)\n",
      "(17, ['AMB_MON_03', 'AMB_MON_04'], '=> ', 0.86500503933141326)\n",
      "(18, ['AMB_MON_01', 'AMB_MON_02'], '=> ', 0.84067963814124302)\n",
      "(19, ['AMB_MON_01', 'EOP_MON_02'], '=> ', 0.87268248696196882)\n",
      "(20, ['AMB_MON_02', 'AMB_MON_03'], '=> ', 0.85860087188339917)\n",
      "(21, ['AMB_MON_02', 'EOP_MON_02'], '=> ', 0.89381155430112691)\n",
      "(22, ['AMB_MON_02', 'EOP_MON_03'], '=> ', 0.87928217608697934)\n",
      "(23, ['AMB_MON_03', 'EOP_MON_03'], '=> ', 0.89181145132749751)\n",
      "(24, ['NB_MON_01_CNT', 'NB_MON_02_CNT'], '=> ', 0.81377480299834137)\n",
      "(25, ['TOP14_CITY', 'TOP9_CITY'], '=> ', 0.89911103737930964)\n",
      "(26, ['C_AMT_L3_MON_06', 'D_AMT_L3_MON_06'], '=> ', 0.99829710769214131)\n",
      "(27, ['D_AMT_L3_MON_06', 'MAX_C_AMT_L3_MON_06'], '=> ', 0.99190862870583796)\n",
      "(28, ['D_AMT_L3_MON_01', 'D_AMT_L3_MON_06'], '=> ', 0.85259048626117018)\n",
      "(29, ['C_AMT_L3_MON_01', 'D_AMT_L3_MON_06'], '=> ', 0.85598361933956602)\n",
      "(30, ['D_AMT_L3_MON_06', 'MAX_C_AMT_L3_MON_01'], '=> ', 0.88785938460366431)\n",
      "(31, ['C_AMT_L3_MON_06', 'MAX_C_AMT_L3_MON_06'], '=> ', 0.99338128253599656)\n",
      "(32, ['C_AMT_L3_MON_06', 'D_AMT_L3_MON_01'], '=> ', 0.85237406648272263)\n",
      "(33, ['C_AMT_L3_MON_01', 'C_AMT_L3_MON_06'], '=> ', 0.85552119414772332)\n",
      "(34, ['C_AMT_L3_MON_06', 'MAX_C_AMT_L3_MON_01'], '=> ', 0.88701290808857503)\n",
      "(35, ['D_AMT_L3_MON_01', 'MAX_C_AMT_L3_MON_06'], '=> ', 0.8193879806352411)\n",
      "(36, ['C_AMT_L3_MON_01', 'MAX_C_AMT_L3_MON_06'], '=> ', 0.82309649447103927)\n",
      "(37, ['MAX_C_AMT_L3_MON_01', 'MAX_C_AMT_L3_MON_06'], '=> ', 0.88834340830921943)\n",
      "(38, ['C_AMT_L3_MON_05', 'D_AMT_L3_MON_05'], '=> ', 0.95619825386283852)\n",
      "(39, ['D_AMT_L3_MON_04', 'D_AMT_L3_MON_05'], '=> ', 0.81168371285356389)\n",
      "(40, ['C_AMT_L3_MON_04', 'D_AMT_L3_MON_05'], '=> ', 0.80529046753911571)\n",
      "(41, ['C_AMT_L3_MON_05', 'D_AMT_L3_MON_04'], '=> ', 0.81817153338143545)\n",
      "(42, ['D_COUNT_L3_MON_04', 'D_COUNT_L3_MON_05'], '=> ', 0.80028183805272401)\n",
      "(43, ['C_AMT_L3_MON_04', 'D_AMT_L3_MON_04'], '=> ', 0.98038908085386367)\n",
      "(44, ['D_COUNT_L3_MON_03', 'D_COUNT_L3_MON_04'], '=> ', 0.81285070622217914)\n",
      "(45, ['C_AMT_L3_MON_03', 'D_AMT_L3_MON_03'], '=> ', 0.99628299061176129)\n",
      "(46, ['D_AMT_L3_MON_03', 'MAX_C_AMT_L3_MON_03'], '=> ', 0.90422052960851518)\n",
      "(47, ['C_AMT_L3_MON_03', 'MAX_C_AMT_L3_MON_03'], '=> ', 0.91736297791980859)\n",
      "(48, ['D_COUNT_L3_MON_02', 'D_COUNT_L3_MON_03'], '=> ', 0.81201735190222213)\n",
      "(49, ['C_AMT_L3_MON_02', 'D_AMT_L3_MON_02'], '=> ', 0.94250864452669258)\n",
      "(50, ['D_COUNT_L3_MON_01', 'D_COUNT_L3_MON_02'], '=> ', 0.82208778011472117)\n",
      "(51, ['C_AMT_L3_MON_01', 'D_AMT_L3_MON_01'], '=> ', 0.97888251533817894)\n",
      "(52, ['D_AMT_L3_MON_01', 'MAX_C_AMT_L3_MON_01'], '=> ', 0.89139881013116462)\n",
      "(53, ['C_AMT_L3_MON_01', 'MAX_C_AMT_L3_MON_01'], '=> ', 0.92084653880547762)\n"
     ]
    }
   ],
   "source": [
    "cols=[]\n",
    "i=0\n",
    "for col in cor.columns.values:\n",
    "    for index in cor[col].index:\n",
    "        if(cor.get_value(index,col) > 0.80 or cor.get_value(index,col) < -0.80) and (index != col ) and sorted((index,col)) not in cols:\n",
    "            i+=1\n",
    "            tpl = (index,col)\n",
    "            cols.append(sorted(tpl))\n",
    "            print ( i,sorted(tpl),'=> ',cor.get_value(index,col))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols_0= [i[0] for i in cols]\n",
    "cols_1= [i[1] for i in cols]\n",
    "#cols_0 = list(set(cols_0))\n",
    "cols_0.sort()\n",
    "#cols_1 = list(set(cols_1))\n",
    "cols_1.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_rem=[]\n",
    "for col in cols_0:\n",
    "    if col in cols_1:\n",
    "        col_rem.append(col)\n",
    "col_rem = list(set(col_rem))\n",
    "\n",
    "cols_0 = list(set(cols_0))\n",
    "for col in col_rem:\n",
    "    if col in cols_0:\n",
    "        cols_0.remove(col)\n",
    "len(col_rem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.drop(col_rem, axis=1,inplace=True)\n",
    "test.drop(col_rem,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cols_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.drop(cols_0, axis=1,inplace=True)\n",
    "test.drop(cols_0,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(233876, 76)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 76)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Arkajit\\\\Anaconda2\\\\envs\\\\TFENV\\\\CrossSellTarget\\\\PrunedDS.zip'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "train.to_csv('CrossSellTarget\\\\PrunedDS\\\\train_pruned.csv')\n",
    "test.to_csv('CrossSellTarget\\\\PrunedDS\\\\test_pruned.csv')\n",
    "shutil.make_archive(\"CrossSellTarget\\\\PrunedDS\", \"zip\", \"CrossSellTarget\\\\PrunedDS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.datasets import make_classification\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "X, y = make_classification(n_samples=5000, n_features=2, n_informative=2,\n",
    "...                            n_redundant=0, n_repeated=0, n_classes=3,\n",
    "...                            n_clusters_per_class=1,\n",
    "...                            weights=[0.01, 0.05, 0.94],\n",
    "...                            class_sep=0.8, random_state=0)\n",
    "\n",
    "\n",
    "ros = RandomOverSampler(random_state=0)\n",
    "X_resampled, y_resampled = ros.fit_sample(X, y)\n",
    "print(sorted(Counter(y_resampled).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arkajit\\Anaconda2\\envs\\TFENV\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\Users\\Arkajit\\Anaconda2\\envs\\TFENV\\lib\\site-packages\\sklearn\\grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn import cross_validation, metrics   #Additional scklearn functions\n",
    "from sklearn.grid_search import GridSearchCV   #Perforing grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = train.as_matrix()\n",
    "y_train = y_train.as_matrix()\n",
    "x_test = test.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 229414), (1, 4462)]\n",
      "[(0, 229414), (1, 229414)]\n"
     ]
    }
   ],
   "source": [
    "ros = RandomOverSampler(random_state=0)\n",
    "print(sorted(Counter(y_train).items()))\n",
    "X_resampled, y_resampled = ros.fit_sample(x_train, y_train)\n",
    "print(sorted(Counter(y_resampled).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import cross_val_score , LeaveOneOut, KFold\n",
    "from scipy.stats import sem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val(X_train,y_train,model,K):\n",
    "    #loo=LeaveOneOut(X_train[:].shape[0])\n",
    "    cv = KFold(len(y_train),K,shuffle=True,random_state=0)\n",
    "    scores = cross_val_score(model,X_train,y_train,cv=cv)\n",
    "    print scores\n",
    "    print \"Mean score: {0:3f} (+/- {1:.3f})\".format(np.mean(scores),sem(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pca = PCA(n_components=20)\n",
    "#pca.fit(X_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#score = pca.explained_variance_ratio_\n",
    "#V = pca.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train_trans = pca.transform(X_resampled)\n",
    "x_test_trans = pca.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = LogisticRegression()\n",
    "#model = SGDClassifier()\n",
    "#model = LogisticRegressionCV()\n",
    "model = RandomForestClassifier(max_features = None , n_jobs=2)\n",
    "#model = XGBClassifier(n_jobs=2)\n",
    "#model = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=2, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model.fit(X_resampled,y_resampled)\n",
    "model.fit(X_train,y_train)\n",
    "#model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred=model.predict(x_test_trans)\n",
    "y_pred=model.predict(x_test_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.78307657  0.78235462  0.78530758  0.78431319  0.78277393]\n",
      "Mean score: 0.783565 (+/- 0.001)\n"
     ]
    }
   ],
   "source": [
    "cross_val(X_train,y_train,model,5) # xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.6770463   0.67384523  0.68176865  0.6799842   0.67122541]\n",
      "Mean score: 0.676774 (+/- 0.002)\n"
     ]
    }
   ],
   "source": [
    "cross_val(X_train,y_train,model,5) # LogisticRegressionCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val(X_train,y_train,model,5) # RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#y_pred = le.inverse_transform(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = pd.DataFrame(y_pred,columns=['RESPONDERS'])\n",
    "y_pred.index = test.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Arkajit\\\\Anaconda2\\\\envs\\\\TFENV\\\\CrossSellTarget\\\\submission.zip'"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "y_pred.to_csv('CrossSellTarget\\\\submission\\\\sample_submission.csv')\n",
    "shutil.make_archive(\"CrossSellTarget\\\\submission\", \"zip\", \"CrossSellTarget\\\\submission\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
