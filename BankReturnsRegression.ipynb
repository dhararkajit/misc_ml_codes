{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('hackerearth_DL\\\\Problem1\\\\train.csv')\n",
    "test = pd.read_csv('hackerearth_DL\\\\Problem1\\\\test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.index = train['portfolio_id']\n",
    "test.index = test['portfolio_id']\n",
    "\n",
    "train.drop(['portfolio_id'],axis=1,inplace=True)\n",
    "test.drop(['portfolio_id'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['start_date'] = train['start_date'].apply(lambda x : dt.strptime(str(x),'%Y%m%d'))\n",
    "train['creation_date'] = train['creation_date'].apply(lambda x : dt.strptime(str(x), '%Y%m%d'))\n",
    "\n",
    "test['start_date'] = test['start_date'].apply(lambda x : dt.strptime(str(x),'%Y%m%d'))\n",
    "test['creation_date'] = test['creation_date'].apply(lambda x : dt.strptime(str(x), '%Y%m%d'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['sell_date'] = train['sell_date'].apply(lambda x : dt.strptime(str(x),'%Y%m%d'))\n",
    "test['sell_date'] = test['sell_date'].apply(lambda x : dt.strptime(str(x), '%Y%m%d'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.drop(['desk_id','office_id'],axis=1,inplace=True)\n",
    "test.drop(['desk_id','office_id'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'pf_category', u'start_date', u'sold', u'country_code',\n",
       "       u'euribor_rate', u'currency', u'libor_rate', u'bought',\n",
       "       u'creation_date', u'indicator_code', u'sell_date', u'type',\n",
       "       u'hedge_value', u'status', u'return'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = train['return']\n",
    "x_train = train\n",
    "x_train.drop(['return'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pf_category 0\n",
      "start_date 0\n",
      "sold 2\n",
      "country_code 0\n",
      "euribor_rate 0\n",
      "currency 0\n",
      "libor_rate 474\n",
      "bought 2\n",
      "creation_date 0\n",
      "indicator_code 5699\n",
      "sell_date 0\n",
      "type 0\n",
      "hedge_value 5701\n",
      "status 3084\n"
     ]
    }
   ],
   "source": [
    "for col in x_train.columns:\n",
    "    print col,x_train[col].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pf_category 0\n",
      "start_date 0\n",
      "sold 0\n",
      "country_code 0\n",
      "euribor_rate 0\n",
      "currency 0\n",
      "libor_rate 265\n",
      "bought 0\n",
      "creation_date 0\n",
      "indicator_code 2851\n",
      "sell_date 0\n",
      "type 0\n",
      "hedge_value 2851\n",
      "status 1457\n"
     ]
    }
   ],
   "source": [
    "for col in test.columns:\n",
    "    print col,test[col].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pf_category               object\n",
       "start_date        datetime64[ns]\n",
       "sold                     float64\n",
       "country_code              object\n",
       "euribor_rate             float64\n",
       "currency                  object\n",
       "libor_rate               float64\n",
       "bought                   float64\n",
       "creation_date     datetime64[ns]\n",
       "indicator_code            object\n",
       "sell_date         datetime64[ns]\n",
       "type                      object\n",
       "hedge_value               object\n",
       "status                    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=x_train.join(pd.get_dummies(x_train['pf_category'],prefix='pf_cat'))\n",
    "x_train=x_train.join(pd.get_dummies(x_train['hedge_value'],prefix='hf_cat'))\n",
    "x_train=x_train.join(pd.get_dummies(x_train['status'],prefix='st_cat'))\n",
    "x_train=x_train.join(pd.get_dummies(x_train['type'],prefix='type_cat'))\n",
    "x_train=x_train.join(pd.get_dummies(x_train['currency'],prefix='c_cat'))\n",
    "x_train=x_train.join(pd.get_dummies(x_train['indicator_code'],prefix='ic_cat'))\n",
    "x_train=x_train.join(pd.get_dummies(x_train['country_code'],prefix='cc_cat'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test=test.join(pd.get_dummies(test['pf_category'],prefix='pf_cat'))\n",
    "test=test.join(pd.get_dummies(test['hedge_value'],prefix='hf_cat'))\n",
    "test=test.join(pd.get_dummies(test['status'],prefix='st_cat'))\n",
    "test=test.join(pd.get_dummies(test['type'],prefix='type_cat'))\n",
    "test=test.join(pd.get_dummies(test['currency'],prefix='c_cat'))\n",
    "test=test.join(pd.get_dummies(test['indicator_code'],prefix='ic_cat'))\n",
    "test=test.join(pd.get_dummies(test['country_code'],prefix='cc_cat'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.drop(['pf_category','country_code','currency','indicator_code','status','hedge_value','type'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test.drop(['pf_category','country_code','currency','indicator_code','status','hedge_value','type'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_date</th>\n",
       "      <th>sold</th>\n",
       "      <th>euribor_rate</th>\n",
       "      <th>libor_rate</th>\n",
       "      <th>bought</th>\n",
       "      <th>creation_date</th>\n",
       "      <th>sell_date</th>\n",
       "      <th>pf_cat_A</th>\n",
       "      <th>pf_cat_B</th>\n",
       "      <th>pf_cat_C</th>\n",
       "      <th>...</th>\n",
       "      <th>c_cat_EUR</th>\n",
       "      <th>c_cat_GBP</th>\n",
       "      <th>c_cat_JPY</th>\n",
       "      <th>c_cat_USD</th>\n",
       "      <th>ic_cat_True</th>\n",
       "      <th>cc_cat_M</th>\n",
       "      <th>cc_cat_N</th>\n",
       "      <th>cc_cat_T</th>\n",
       "      <th>cc_cat_U</th>\n",
       "      <th>cc_cat_Z</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>portfolio_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PF00001002</th>\n",
       "      <td>2004-07-20</td>\n",
       "      <td>110000000.0</td>\n",
       "      <td>0.02074</td>\n",
       "      <td>2.332216</td>\n",
       "      <td>1.098097e+08</td>\n",
       "      <td>2004-07-20</td>\n",
       "      <td>2004-08-12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PF00001003</th>\n",
       "      <td>2004-07-09</td>\n",
       "      <td>176671000.0</td>\n",
       "      <td>0.02074</td>\n",
       "      <td>5.269617</td>\n",
       "      <td>1.760084e+08</td>\n",
       "      <td>2004-07-23</td>\n",
       "      <td>2004-08-12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PF00001005</th>\n",
       "      <td>2004-07-23</td>\n",
       "      <td>56474000.0</td>\n",
       "      <td>0.02074</td>\n",
       "      <td>2.332216</td>\n",
       "      <td>5.637953e+07</td>\n",
       "      <td>2004-07-23</td>\n",
       "      <td>2004-08-17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PF00001006</th>\n",
       "      <td>2004-06-09</td>\n",
       "      <td>164813000.0</td>\n",
       "      <td>0.02074</td>\n",
       "      <td>2.332216</td>\n",
       "      <td>1.645088e+08</td>\n",
       "      <td>2004-07-23</td>\n",
       "      <td>2004-07-13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PF00001007</th>\n",
       "      <td>2004-06-09</td>\n",
       "      <td>140800000.0</td>\n",
       "      <td>0.02074</td>\n",
       "      <td>2.332216</td>\n",
       "      <td>1.405402e+08</td>\n",
       "      <td>2004-07-23</td>\n",
       "      <td>2004-07-13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             start_date         sold  euribor_rate  libor_rate        bought  \\\n",
       "portfolio_id                                                                   \n",
       "PF00001002   2004-07-20  110000000.0       0.02074    2.332216  1.098097e+08   \n",
       "PF00001003   2004-07-09  176671000.0       0.02074    5.269617  1.760084e+08   \n",
       "PF00001005   2004-07-23   56474000.0       0.02074    2.332216  5.637953e+07   \n",
       "PF00001006   2004-06-09  164813000.0       0.02074    2.332216  1.645088e+08   \n",
       "PF00001007   2004-06-09  140800000.0       0.02074    2.332216  1.405402e+08   \n",
       "\n",
       "             creation_date  sell_date  pf_cat_A  pf_cat_B  pf_cat_C    ...     \\\n",
       "portfolio_id                                                           ...      \n",
       "PF00001002      2004-07-20 2004-08-12         0         1         0    ...      \n",
       "PF00001003      2004-07-23 2004-08-12         1         0         0    ...      \n",
       "PF00001005      2004-07-23 2004-08-17         1         0         0    ...      \n",
       "PF00001006      2004-07-23 2004-07-13         1         0         0    ...      \n",
       "PF00001007      2004-07-23 2004-07-13         0         1         0    ...      \n",
       "\n",
       "              c_cat_EUR  c_cat_GBP  c_cat_JPY  c_cat_USD  ic_cat_True  \\\n",
       "portfolio_id                                                            \n",
       "PF00001002            0          0          0          1            0   \n",
       "PF00001003            0          1          0          0            0   \n",
       "PF00001005            0          0          0          1            0   \n",
       "PF00001006            0          0          0          1            0   \n",
       "PF00001007            0          0          0          1            0   \n",
       "\n",
       "              cc_cat_M  cc_cat_N  cc_cat_T  cc_cat_U  cc_cat_Z  \n",
       "portfolio_id                                                    \n",
       "PF00001002           0         0         1         0         0  \n",
       "PF00001003           0         1         0         0         0  \n",
       "PF00001005           0         0         1         0         0  \n",
       "PF00001006           0         0         1         0         0  \n",
       "PF00001007           0         0         1         0         0  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train['sell_minus_start'] = x_train['sell_date'] - x_train['start_date']\n",
    "x_train['sell_minus_creation'] = x_train['sell_date'] - x_train['creation_date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test['sell_minus_start'] = test['sell_date'] - test['start_date']\n",
    "test['sell_minus_creation'] = test['sell_date'] - test['creation_date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train['sell_minus_start']=x_train['sell_minus_start'].apply(lambda x : x.days)\n",
    "x_train['sell_minus_creation']=x_train['sell_minus_creation'].apply(lambda x : x.days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test['sell_minus_start']=test['sell_minus_start'].apply(lambda x : x.days)\n",
    "test['sell_minus_creation']=test['sell_minus_creation'].apply(lambda x : x.days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.drop(['start_date','creation_date','sell_date'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test.drop(['start_date','creation_date','sell_date'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing as pp\n",
    "from random import Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arkajit\\Anaconda2\\envs\\TFENV\\lib\\site-packages\\pandas\\core\\indexing.py:179: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "for i in list(x_train[x_train.libor_rate.isnull() == True].index):\n",
    "    if (str(x_train['libor_rate'].loc[i]) == str(np.nan)):\n",
    "        x_train['libor_rate'].loc[i] = np.random.normal(loc=0.998066, scale= 1.457977)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in list(test[test.libor_rate.isnull() == True].index):\n",
    "    if (str(test['libor_rate'].loc[i]) == str(np.nan)):\n",
    "        test['libor_rate'].loc[i] = np.random.normal(loc=0.930464, scale= 1.387474)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in list(x_train[x_train.sold.isnull() == True].index):\n",
    "    if (str(x_train['sold'].loc[i]) == str(np.nan)):\n",
    "        x_train['sold'].loc[i] = np.random.normal(loc=1.019740e+08, scale= 1.928066e+08)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in list(x_train[x_train.bought.isnull() == True].index):\n",
    "    if (str(x_train['bought'].loc[i]) == str(np.nan)):\n",
    "        x_train['bought'].loc[i] = np.random.normal(loc=1.018914e+08, scale= 1.927472e+08)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc = pp.StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.drop(['pf_cat_E','type_cat_G'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'sold', u'euribor_rate', u'libor_rate', u'bought', u'pf_cat_A',\n",
       "       u'pf_cat_B', u'pf_cat_C', u'pf_cat_D', u'hf_cat_False', u'hf_cat_True',\n",
       "       u'st_cat_True', u'type_cat_A', u'type_cat_B', u'type_cat_C',\n",
       "       u'type_cat_D', u'type_cat_E', u'type_cat_F', u'type_cat_H',\n",
       "       u'c_cat_CHF', u'c_cat_EUR', u'c_cat_GBP', u'c_cat_JPY', u'c_cat_USD',\n",
       "       u'ic_cat_True', u'cc_cat_M', u'cc_cat_N', u'cc_cat_T', u'cc_cat_U',\n",
       "       u'cc_cat_Z', u'sell_minus_start', u'sell_minus_creation'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain = sc.transform(x_train)\n",
    "xtest = sc.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(xtrain, y_train, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "mingw_path = 'C:\\\\mingw-w64\\\\x86_64-5.3.0-posix-seh-rt_v4-rev0\\\\mingw64\\\\bin'\n",
    "\n",
    "os.environ['PATH'] = mingw_path + ';' + os.environ['PATH']\n",
    "import xgboost as xg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost.sklearn import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_val(X_train,y_train,model,K):\n",
    "    #loo=LeaveOneOut(X_train[:].shape[0])\n",
    "    cv = KFold(len(y_train),K,shuffle=True,random_state=0)\n",
    "    scores = cross_val_score(model,X_train,y_train,cv=cv)\n",
    "    print scores\n",
    "    print \"Mean score: {0:3f} (+/- {1:.3f})\".format(np.mean(scores),sem(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.95963553  0.95791634  0.26893214  0.927135    0.8401113   0.90328354\n",
      "  0.8198776   0.94908176  0.96235788  0.93665749]\n",
      "Mean score: 0.852499 (+/- 0.067)\n"
     ]
    }
   ],
   "source": [
    "cross_val(X_train,Y_train,model,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(xtrain,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = model.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'PF00001001', u'PF00001004', u'PF00001009', u'PF00001013',\n",
       "       u'PF00001014', u'PF00001015', u'PF00001017', u'PF00001023',\n",
       "       u'PF00001024', u'PF00001025',\n",
       "       ...\n",
       "       u'PF00013543', u'PF00013544', u'PF00013742', u'PF00014031',\n",
       "       u'PF00014093', u'PF00014118', u'PF00014120', u'PF00014123',\n",
       "       u'PF00014127', u'PF00014147'],\n",
       "      dtype='object', name=u'portfolio_id', length=4801)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(Y_pred, index= test.index,columns=['return'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('hackerearth_DL\\\\Problem1\\\\submit_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
